{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42323f23-c9db-488b-a20d-6ee873d6564d",
   "metadata": {},
   "source": [
    "Code from : https://github.com/online-ml/river/blob/main/river/ensemble/ewa.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadb31d-588a-436a-8a06-ff950ffa3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import typing\n",
    "\n",
    "from river import base\n",
    "from river import linear_model as lm\n",
    "from river import optim\n",
    "from river import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03046a6-1892-4cd4-8889-3192f070e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import datasets\n",
    "from river import ensemble\n",
    "from river import evaluate\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "from river import optim\n",
    "from river import preprocessing\n",
    "from river import stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaf5a36-0238-49ea-b42c-d04e82c52633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class EWARegressor1(base.Ensemble, base.Regressor):\n",
    "    \"\"\"Exponentially Weighted Average regressor.\n",
    "    Parameters\n",
    "    ----------\n",
    "    models\n",
    "        The regressors to hedge.\n",
    "    loss\n",
    "        The loss function that has to be minimized. Defaults to `optim.losses.Squared`.\n",
    "    learning_rate\n",
    "        The learning rate by which the model weights are multiplied at each iteration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        models: typing.List[base.Regressor],\n",
    "        loss: optim.losses.RegressionLoss = None,\n",
    "        learning_rate=0.5,\n",
    "    ):\n",
    "        super().__init__(models)\n",
    "        self.loss = optim.losses.Squared() if loss is None else loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = [1.0] * len(models)\n",
    "\n",
    "    def learn_predict_one(self, x, y):\n",
    "\n",
    "        y_pred_mean = 0.0\n",
    "\n",
    "        # Make a prediction and update the weights accordingly for each model\n",
    "        total = 0\n",
    "        for i, regressor in enumerate(self):\n",
    "            y_pred = regressor.predict_one(x=x)\n",
    "            y_pred_mean += self.weights[i] * (y_pred - y_pred_mean) / len(self)\n",
    "            loss = self.loss(y_true=y, y_pred=y_pred)\n",
    "            self.weights[i] *= math.exp(-self.learning_rate * loss)\n",
    "            total += self.weights[i]\n",
    "            regressor.learn_one(x, y)\n",
    "\n",
    "        # Normalize the weights so that they sum up to 1\n",
    "        if total:\n",
    "            for i, _ in enumerate(self.weights):\n",
    "                self.weights[i] /= total\n",
    "\n",
    "        return y_pred_mean\n",
    "\n",
    "    def learn_one(self, x, y):\n",
    "        self.learn_predict_one(x, y)\n",
    "        return self\n",
    "\n",
    "    def predict_one(self, x):\n",
    "        return sum(\n",
    "            model.predict_one(x) * weight for model, weight in zip(self, self.weights)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852b45d7-a36d-4a99-a877-2b9e4199b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD MAE: 0.555971\n",
      "RMSProp MAE: 0.528284\n",
      "AdaGrad MAE: 0.481461\n"
     ]
    }
   ],
   "source": [
    "optimizers = [\n",
    "     optim.SGD(0.01),\n",
    "     optim.RMSProp(),\n",
    "     optim.AdaGrad()]\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    dataset = datasets.TrumpApproval()\n",
    "    metric = metrics.MAE()\n",
    "    model = (\n",
    "         preprocessing.StandardScaler() |\n",
    "         linear_model.LinearRegression(\n",
    "             optimizer=optimizer,\n",
    "             intercept_lr=.1\n",
    "         )\n",
    "     )\n",
    "\n",
    "    print(optimizer, evaluate.progressive_val_score(dataset, model, metric))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "575aec9f-9c74-49a4-b75f-11292ad30989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAE: 0.494307"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.TrumpApproval()\n",
    "metric = metrics.MAE()\n",
    "hedge = (\n",
    "     preprocessing.StandardScaler() |\n",
    "     EWARegressor1(\n",
    "         [\n",
    "             linear_model.LinearRegression(optimizer=o, intercept_lr=.1)\n",
    "             for o in optimizers\n",
    "         ],\n",
    "         learning_rate=0.005\n",
    "     )\n",
    " )\n",
    "evaluate.progressive_val_score(dataset, hedge, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82667b08-8e63-4583-8961-6692472447b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
